<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control</title>

    <meta name="description" content="Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <meta property="og:image" content="https://robot-teaching.github.io/assets/images/teaser.gif">
    <meta property="og:image:type" content="image/gif">
    <meta property="og:image:width" content="600">
    <meta property="og:image:height" content="400">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://robot-teaching.github.io/"/>
    <meta property="og:title" content="Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control" />
    <meta property="og:description" content="Project page for Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control" />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control" />
    <meta name="twitter:description" content="Project page for Learning to Learn Faster from Human Feedbackwith Language Model Predictive Control." />
    <meta name="twitter:image" content="https://robot-teaching.github.io/assets/images/teaser.png" />


    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-HQJ6G7EKRG"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-HQJ6G7EKRG');
    </script>
    <style>
    #myVideo {
      width: 100%;
      height: auto;
      object-fit: cover; /* This will make the video cover the full area of the tag */
      border-radius: 5px; /* If you want to keep the border-radius */
    }
  </style>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models
                        </h1>
                        <!-- <h3 class="title is-4 conference-authors"><a target="_blank" href="https://icml.cc/">ICML 2023</a>
                    </h3> -->
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                               Chen Wang, 
                               Fei Xia, 
                               Wenhao Yu, 
                               Tingnan Zhang, 
                               Ruohan Zhang,
                               C. Karen Liu, 
                               Li Fei-Fei,
                               Jie Tan,
                               Jacky Liang
                              </span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><b>Google DeepMind</b>, <b>Stanford University</b></span>
                            
                        </div>
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>PDF</span>
                                    </a>
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                    <!-- <a target="_blank" href="??"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fa-solid fa-desktop"></i>
                                        </span>
                                        <span>Colab</span>
                                    </a> -->
                                    <!-- <a href="#demo"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-robot"></i>
                                        </span>
                                        <span>Demo</span>
                                    </a> -->
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" style="padding: 0">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <video poster="" id="" autoplay muted loop width="100%" playsinline onclick="if(!this.hasAttribute('controls')) {this.setAttribute('controls', 'controls');}">
                    <source src="assets/videos/main.mp4" type="video/mp4">
                </video>
                 
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                            Learning to perform manipulation tasks from human videos is a promising approach for teaching robots. However, many manipulation tasks require changing control parameters during task execution, such as force, which visual data alone cannot capture. In this work, we leverage sensing devices such as armbands that measure human muscle activities and microphones that record sound, to capture the details in the human manipulation process, and enable robots to extract task plans and control parameters to perform the same task. To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy that enables Vision Language Models to reason about multimodal human demonstration data --- videos coupled with muscle or audio signals. By progressively integrating information from each modality, CoM refines a task plan and generates detailed control parameters, enabling robots to perform manipulation tasks based on a single multimodal human video prompt. Our experiments show that CoM delivers a threefold improvement in accuracy for extracting task plans and control parameters compared to baselines, with generalization to new task setups and objects in real-world robot experiments. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a href="https://robot-teaching.github.io/">robot-teaching</a>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

<script>
    document.addEventListener('DOMContentLoaded', (event) => {
      let options = {
        root: null, // using the viewport as the bounding box
        rootMargin: '0px',
        threshold: 0.5 // play when 50% of the video is visible
      };
  
      let observer = new IntersectionObserver((entries, observer) => { 
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            entry.target.play();
          } else {
            entry.target.pause();
          }
        });
      }, options);
  
      let video = document.getElementById('videoInView');
      observer.observe(video);
    });
  </script>

</html>
